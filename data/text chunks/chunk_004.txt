atures might reached near to the converging stage where only it needs a small adjustment that means suppose um our two weights weight one is a 0.5 and weight 2 is here we are having 0.9 right you assume that we need to bring this weights into uh the convergence point for example 0.3 okay so you assume this is the zero value of value for converging Point okay so we have to bring this two parameters in uh towards the 0.3 so when we are are bringing this W1 to the 0.3 we need small adjustment Okay small adjustment that means small updation right but when you are um bringing this 0.9 to 0.3 we need some uh some higher value adjustment okay so some higher value adjustment so this kind of uh uh updation can be done by using the different learning rates okay so learning rate should be different to make this kind of adjustment to uh make the converging process faster so that is the um purpose the order grid is using a different learning rate for each and every parameters during the training ph